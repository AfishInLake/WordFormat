#! /usr/bin/env python
# @Time    : 2025/12/22 21:47
# @Author  : afish
# @File    : DocxBase.py

from loguru import logger

from wordformat.agent.onnx_infer import onnx_batch_infer, onnx_single_infer
from wordformat.config.config import get_config, init_config
from wordformat.settings import BATCH_SIZE
from wordformat.utils import get_paragraph_xml_fingerprint


class DocxBase:
    def __init__(self, docx_file, configpath):
        from docx import Document

        self.re_dict = {}
        self.docx_file = docx_file
        self.document = Document(docx_file)
        init_config(configpath)
        try:
            self.config_model = get_config()  # é¦–æ¬¡è°ƒç”¨ï¼šè§¦å‘load()
            self.config = self.config_model.model_dump()
            logger.info("é…ç½®æ–‡ä»¶éªŒè¯é€šè¿‡")
        except Exception as e:
            logger.error(f"é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
            raise

    def parse(self) -> list[dict]:
        paragraphs = []
        paragraph_objects = []  # ä¿å­˜åŸå§‹ paragraph å¯¹è±¡ï¼Œç”¨äº fingerprint å’Œæå‰ç»ˆæ­¢
        # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰éç©ºæ®µè½åŠå…¶å¯¹è±¡
        for para in self.document.paragraphs:
            text = para.text.strip()
            if text:
                paragraphs.append(para.text)
                paragraph_objects.append(para)

        result = []

        # ç¬¬äºŒæ­¥ï¼šæŒ‰æ‰¹æ¬¡ï¼ˆæ¯æ‰¹ 128 æ¡ï¼‰è¿›è¡Œæ‰¹é‡æ¨ç†
        batch_size = int(BATCH_SIZE)
        for i in range(0, len(paragraphs), batch_size):
            batch_texts = paragraphs[i : i + batch_size]
            batch_paras = paragraph_objects[i : i + batch_size]

            try:
                # æ‰¹é‡æ¨ç†ï¼ˆå…³é”®ä¿®æ”¹ç‚¹ï¼‰
                batch_results = onnx_batch_infer(batch_texts)
            except Exception as e:
                # æ•´ä¸ª batch æ¨ç†å¤±è´¥ï¼Ÿé™çº§ä¸ºé€æ¡å¤„ç†ï¼ˆå¯é€‰ï¼‰
                logger.error(f"æ‰¹é‡æ¨ç†å¤±è´¥ï¼Œé™çº§åˆ°å•æ¡å¤„ç†: {e}")
                batch_results = [onnx_single_infer(text) for text in batch_texts]

            # ç¬¬ä¸‰æ­¥ï¼šé€æ¡å¤„ç† batch ç»“æœï¼Œåº”ç”¨åå¤„ç†é€»è¾‘
            for _j, (text, para_obj, pred) in enumerate(
                zip(batch_texts, batch_paras, batch_results, strict=False)
            ):
                tag = pred["é¢„æµ‹æ ‡ç­¾"]
                score = pred["é¢„æµ‹æ¦‚ç‡"]

                response = {
                    "category": tag,
                    "score": score,
                    "comment": f"ç½®ä¿¡åº¦ï¼š{score:.4f}",
                    "paragraph": text,
                    "fingerprint": get_paragraph_xml_fingerprint(para_obj),
                }

                # ç½®ä¿¡åº¦è¿‡ä½å¤„ç†
                if score < 0.6:
                    response["category"] = "body_text"
                    response["comment"] = (
                        f"åŸé¢„æµ‹æ ‡ç­¾ä¸º '{tag}'ï¼Œç½®ä¿¡åº¦ {score:.4f} < 0.6ï¼Œå·²å¼ºåˆ¶è®¾ä¸º 'body_text'"
                    )

                logger.info(response)
                result.append(response)

                # é‡åˆ° heading_fulu åˆ™æå‰ç»ˆæ­¢æ•´ä¸ªè§£æ
                if response["category"] == "heading_fulu":
                    return result  # ğŸ‘ˆ ç«‹å³è¿”å›ï¼Œä¸å†å¤„ç†åç»­æ®µè½

        return result
